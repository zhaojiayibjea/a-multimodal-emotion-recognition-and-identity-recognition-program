# 使用指南

2025/2/7 By ZJY

## 描述

一个多模态情感识别程序。本项目可以实现从摄像头+麦克风/视频文件中读取视频，并将视频分割成若干10分钟（可更改）长的片段，并依次处理。

具体地，每个片段会首先进行声纹识别、声音情感识别，得出量化的分数并在数据库中更改。随后，每个视频片段会以每隔五秒截取一帧（可更改）的频率进行面部识别、和面部情感识别，识别结果同样会同步至数据库中。音频处理基于[FunASR](https://github.com/modelscope/FunASR)，视频处理基于[Deepface](https://github.com/serengil/deepface)。



## 快速体验

1. 运行本项目前最好将Python版本调成**3.10**。作者只在Python 3.10上测试过程序，其它版本可能导致运行问题。推荐在venv等虚拟环境中使用项目。

2. 将项目完整下载到本地：

    ```bash
    git clone https://github.com/zhaojiayibjea/chuyan_backend.git
    ```

3. 安装python依赖包：

    在项目的根目录下打开终端，并执行

    ```bash
    pip install -r requirements.txt
    ```

4. 如果电脑上有英伟达显卡且支持CUDA，强烈推荐安装，这可以大幅提升运行效率。

5. 在 `config.py` 文件中配置自己的数据库、输入文件目录、声纹库目录、人脸库目录等信息。

6. 确定检测对象的编号，并在数据库中添加行：

```sql
INSERT INTO scores (id, score) VALUES (你的编号, 0)
```

7. 如果你没有在配置文件中设置使用`实时检测`功能，请在输入文件目录中添加视频文件。

8. 收集检测对象的声音以及人脸样本，在声纹库、人脸库中添加样本。请使用编号作为文件名。

9. 检查运行环境要求，运行`main.py` 文件

 

## 运行结果与调试

由于本项目暂时未完成前端部分，目前只能通过观察数据库中数值的变化查看程序运行的结果。

你可以通过执行：

```sql
SELECT * FROM scores
```

或者其他SQL命令查看结果。

如果你想优化身份识别的结果，可以在`config.py`文件中修改容忍度进行调试。

您可以单独运行`audio_process.py`和`video_process.py`来节省时间。调试方法参看两个文件中

```python
if __name__ == '__main__':
```

 下方的代码。

## 项目文件简介

本项目的功能主要通过这些文件实现：

`config.py`：本程序的配置文件，你可以根据自己的情况调整其中的配置选项。作者在注释中详细介绍了每项的功能。本文档中提到的所有路径都可以在这个文件中更改。

`main.py`：**本程序的入口**，如果想运行整个项目，运行这个文件即可。这个文件实现了待处理视频的获取、分割，调用了音频处理函数`audio_worker()`和视频处理函数`video_worker()`，实现了数据库连接、日志配置的功能。

`realtime.py`：在打开实时功能时本程序生效。实现了实时调用麦克风进行录音，定期分块保存音频，同时实时显示摄像头画面，并在摄像头画面上以条状展示麦克风音量和保存成文件的倒计时。

`audio_process.py`：实现了音频处理的功能，对外使用`audio_worker()`函数作为接口。由于计算量大，作者使用了多线程的写法。

`video_process.py`：实现了视频处理的功能。对外使用`video_worker()`函数作为接口。



## 致谢

本项目使用和参考了若干开源项目，详见：[LICENSE](LICENSE.md)

